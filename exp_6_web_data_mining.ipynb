{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flx0BLDxKD73",
        "outputId": "3c827100-4af7-4c3b-d333-fc809f374f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: first document\n",
            "Query: first document\n",
            "\n",
            "Rank: 1\n",
            "Document ID: doc4\n",
            "Document: Is this the first document?\n",
            "Similarity Score: 1.0\n",
            "----------------------\n",
            "\n",
            "Rank: 2\n",
            "Document ID: doc1\n",
            "Document: This is the first document.\n",
            "Similarity Score: 1.0\n",
            "----------------------\n",
            "\n",
            "Rank: 3\n",
            "Document ID: doc2\n",
            "Document: This document is the second document.\n",
            "Similarity Score: 0.78722297610404\n",
            "----------------------\n",
            "\n",
            "Rank: 4\n",
            "Document ID: doc3\n",
            "Document: And this is the third one.\n",
            "Similarity Score: 0.0\n",
            "----------------------\n",
            "The highest rank cosine score is: 1.0\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "\n",
        "# Load spaCy's English tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample documents stored in a dictionary\n",
        "documents = {\n",
        "    \"doc1\": \"This is the first document.\",\n",
        "    \"doc2\": \"This document is the second document.\",\n",
        "    \"doc3\": \"And this is the third one.\",\n",
        "    \"doc4\": \"Is this the first document?\",\n",
        "}\n",
        "\n",
        "# Preprocessing function to tokenize and remove stopwords/punctuation using spaCy\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.text for token in doc if token.text not in nlp.Defaults.stop_words and token.text not in string.punctuation]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Preprocess documents and store them in a dictionary\n",
        "preprocessed_docs = {doc_id: preprocess_text(doc) for doc_id, doc in documents.items()}\n",
        "\n",
        "# Construct TF-IDF matrix\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_docs.values())\n",
        "\n",
        "# Calculate cosine similarity between query and documents\n",
        "def search(query, tfidf_matrix, tfidf_vectorizer):\n",
        "    preprocessed_query = preprocess_text(query)\n",
        "    query_vector = tfidf_vectorizer.transform([preprocessed_query])\n",
        "\n",
        "    # Calculate cosine similarity between query and documents\n",
        "    similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
        "\n",
        "    # Sort documents based on similarity scores\n",
        "    sorted_indexes = similarity_scores.argsort()[0][::-1]\n",
        "\n",
        "    # Return sorted documents along with their similarity scores\n",
        "    results = [(list(preprocessed_docs.keys())[i], list(documents.values())[i], similarity_scores[0, i]) for i in sorted_indexes]\n",
        "    return results\n",
        "\n",
        "# Get input from user\n",
        "query = input(\"Enter your query: \")\n",
        "\n",
        "# Perform search\n",
        "search_results = search(query, tfidf_matrix, tfidf_vectorizer)\n",
        "\n",
        "# Display search results\n",
        "print(\"Query:\", query)\n",
        "for i, result in enumerate(search_results, start=1):\n",
        "    print(f\"\\nRank: {i}\")\n",
        "    print(\"Document ID:\", result[0])\n",
        "    print(\"Document:\", result[1])\n",
        "    print(\"Similarity Score:\", result[2])\n",
        "    print(\"----------------------\")\n",
        "\n",
        "# Get the highest rank cosine score\n",
        "highest_rank_score = max(result[2] for result in search_results)\n",
        "print(\"The highest rank cosine score is:\", highest_rank_score)"
      ]
    }
  ]
}